


kaggle正在跑
效果一般

run30轮
过拟合

run10轮效果不错
  2025 05 24
  正在跑newV1.py

D:\ProgramData\anaconda3\envs\homework_2_1\python.exe D:/homework/Course_Design_of_artificial_intelligence/third/ResNet/kaggle_dalao/sam_dalao_before/newV1.py
Using device: cuda
数据增强：关闭 | 训练：True | 测试：True
------ 模型结构和参数量 ------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
            Conv2d-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
              ReLU-7           [-1, 64, 56, 56]               0
            Conv2d-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
             ReLU-10           [-1, 64, 56, 56]               0
       BasicBlock-11           [-1, 64, 56, 56]               0
           Conv2d-12           [-1, 64, 56, 56]          36,864
      BatchNorm2d-13           [-1, 64, 56, 56]             128
             ReLU-14           [-1, 64, 56, 56]               0
           Conv2d-15           [-1, 64, 56, 56]          36,864
      BatchNorm2d-16           [-1, 64, 56, 56]             128
             ReLU-17           [-1, 64, 56, 56]               0
       BasicBlock-18           [-1, 64, 56, 56]               0
           Conv2d-19          [-1, 128, 28, 28]          73,728
      BatchNorm2d-20          [-1, 128, 28, 28]             256
             ReLU-21          [-1, 128, 28, 28]               0
           Conv2d-22          [-1, 128, 28, 28]         147,456
      BatchNorm2d-23          [-1, 128, 28, 28]             256
           Conv2d-24          [-1, 128, 28, 28]           8,192
      BatchNorm2d-25          [-1, 128, 28, 28]             256
             ReLU-26          [-1, 128, 28, 28]               0
       BasicBlock-27          [-1, 128, 28, 28]               0
           Conv2d-28          [-1, 128, 28, 28]         147,456
      BatchNorm2d-29          [-1, 128, 28, 28]             256
             ReLU-30          [-1, 128, 28, 28]               0
           Conv2d-31          [-1, 128, 28, 28]         147,456
      BatchNorm2d-32          [-1, 128, 28, 28]             256
             ReLU-33          [-1, 128, 28, 28]               0
       BasicBlock-34          [-1, 128, 28, 28]               0
           Conv2d-35          [-1, 256, 14, 14]         294,912
      BatchNorm2d-36          [-1, 256, 14, 14]             512
             ReLU-37          [-1, 256, 14, 14]               0
           Conv2d-38          [-1, 256, 14, 14]         589,824
      BatchNorm2d-39          [-1, 256, 14, 14]             512
           Conv2d-40          [-1, 256, 14, 14]          32,768
      BatchNorm2d-41          [-1, 256, 14, 14]             512
             ReLU-42          [-1, 256, 14, 14]               0
       BasicBlock-43          [-1, 256, 14, 14]               0
           Conv2d-44          [-1, 256, 14, 14]         589,824
      BatchNorm2d-45          [-1, 256, 14, 14]             512
             ReLU-46          [-1, 256, 14, 14]               0
           Conv2d-47          [-1, 256, 14, 14]         589,824
      BatchNorm2d-48          [-1, 256, 14, 14]             512
             ReLU-49          [-1, 256, 14, 14]               0
       BasicBlock-50          [-1, 256, 14, 14]               0
           Conv2d-51            [-1, 512, 7, 7]       1,179,648
      BatchNorm2d-52            [-1, 512, 7, 7]           1,024
             ReLU-53            [-1, 512, 7, 7]               0
           Conv2d-54            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-55            [-1, 512, 7, 7]           1,024
           Conv2d-56            [-1, 512, 7, 7]         131,072
      BatchNorm2d-57            [-1, 512, 7, 7]           1,024
             ReLU-58            [-1, 512, 7, 7]               0
       BasicBlock-59            [-1, 512, 7, 7]               0
           Conv2d-60            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-61            [-1, 512, 7, 7]           1,024
             ReLU-62            [-1, 512, 7, 7]               0
           Conv2d-63            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-64            [-1, 512, 7, 7]           1,024
             ReLU-65            [-1, 512, 7, 7]               0
       BasicBlock-66            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0
           Linear-68                  [-1, 120]          61,560
================================================================
Total params: 11,238,072
Trainable params: 11,238,072
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 62.79
Params size (MB): 42.87
Estimated Total Size (MB): 106.23
----------------------------------------------------------------
参数量: 11.24M
模型大小: 42.91 MB
FLOPs: 3.65 GFLOPs/图像

==== Epoch 1/30 ====
Train: 100%|██████████| 256/256 [01:20<00:00,  3.20it/s]
Val: 100%|██████████| 64/64 [00:13<00:00,  4.60it/s]
Train Loss: 4.7734 | Val Loss: 4.8103 | Val Acc: 0.0161 | Top-5: 0.0782 | F1: 0.0029
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 2/30 ====
Train: 100%|██████████| 256/256 [01:20<00:00,  3.17it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.93it/s]
Train Loss: 4.5633 | Val Loss: 4.6056 | Val Acc: 0.0210 | Top-5: 0.0944 | F1: 0.0042
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 3/30 ====
Train: 100%|██████████| 256/256 [02:04<00:00,  2.06it/s]
Val: 100%|██████████| 64/64 [00:25<00:00,  2.50it/s]
Train Loss: 4.3915 | Val Loss: 4.3818 | Val Acc: 0.0469 | Top-5: 0.1614 | F1: 0.0222

==== Epoch 4/30 ====
Train: 100%|██████████| 256/256 [01:21<00:00,  3.13it/s]
Val: 100%|██████████| 64/64 [00:12<00:00,  5.15it/s]
Train Loss: 4.2160 | Val Loss: 4.2955 | Val Acc: 0.0484 | Top-5: 0.1795 | F1: 0.0248
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 5/30 ====
Train: 100%|██████████| 256/256 [01:14<00:00,  3.43it/s]
Val: 100%|██████████| 64/64 [00:12<00:00,  5.22it/s]
Train Loss: 4.0886 | Val Loss: 4.4856 | Val Acc: 0.0465 | Top-5: 0.1765 | F1: 0.0207

==== Epoch 6/30 ====
Train: 100%|██████████| 256/256 [01:13<00:00,  3.47it/s]
Val: 100%|██████████| 64/64 [00:13<00:00,  4.76it/s]
Train Loss: 3.9525 | Val Loss: 4.1445 | Val Acc: 0.0704 | Top-5: 0.2445 | F1: 0.0433
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 7/30 ====
Train: 100%|██████████| 256/256 [01:24<00:00,  3.01it/s]
Val: 100%|██████████| 64/64 [00:13<00:00,  4.65it/s]
Train Loss: 3.8217 | Val Loss: 4.0718 | Val Acc: 0.0807 | Top-5: 0.2631 | F1: 0.0509
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 8/30 ====
Train: 100%|██████████| 256/256 [01:23<00:00,  3.05it/s]
Val: 100%|██████████| 64/64 [00:13<00:00,  4.66it/s]
Train Loss: 3.5035 | Val Loss: 3.7939 | Val Acc: 0.1149 | Top-5: 0.3389 | F1: 0.0873

==== Epoch 9/30 ====
Train: 100%|██████████| 256/256 [01:24<00:00,  3.04it/s]
Val: 100%|██████████| 64/64 [00:14<00:00,  4.32it/s]
Train Loss: 3.3804 | Val Loss: 3.7575 | Val Acc: 0.1286 | Top-5: 0.3452 | F1: 0.1005

==== Epoch 10/30 ====
Train: 100%|██████████| 256/256 [01:28<00:00,  2.88it/s]
Val: 100%|██████████| 64/64 [00:14<00:00,  4.48it/s]
Train Loss: 3.2960 | Val Loss: 3.7465 | Val Acc: 0.1222 | Top-5: 0.3560 | F1: 0.0990

==== Epoch 11/30 ====
Train: 100%|██████████| 256/256 [01:30<00:00,  2.83it/s]
Val: 100%|██████████| 64/64 [00:13<00:00,  4.58it/s]
Train Loss: 3.2376 | Val Loss: 3.7309 | Val Acc: 0.1325 | Top-5: 0.3658 | F1: 0.1085
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 12/30 ====
Train: 100%|██████████| 256/256 [01:29<00:00,  2.87it/s]
Val: 100%|██████████| 64/64 [00:15<00:00,  4.21it/s]
Train Loss: 3.1650 | Val Loss: 3.7311 | Val Acc: 0.1276 | Top-5: 0.3663 | F1: 0.1047

==== Epoch 13/30 ====
Train: 100%|██████████| 256/256 [01:37<00:00,  2.62it/s]
Val: 100%|██████████| 64/64 [00:17<00:00,  3.69it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 3.0801 | Val Loss: 3.7375 | Val Acc: 0.1369 | Top-5: 0.3677 | F1: 0.1156

==== Epoch 14/30 ====
Train: 100%|██████████| 256/256 [01:32<00:00,  2.78it/s]
Val: 100%|██████████| 64/64 [00:15<00:00,  4.03it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.9956 | Val Loss: 3.7427 | Val Acc: 0.1311 | Top-5: 0.3741 | F1: 0.1132

==== Epoch 15/30 ====
Train: 100%|██████████| 256/256 [01:30<00:00,  2.83it/s]
Val: 100%|██████████| 64/64 [00:15<00:00,  4.09it/s]
Train Loss: 2.8642 | Val Loss: 3.7064 | Val Acc: 0.1291 | Top-5: 0.3780 | F1: 0.1101

==== Epoch 16/30 ====
Train: 100%|██████████| 256/256 [01:30<00:00,  2.83it/s]
Val: 100%|██████████| 64/64 [00:19<00:00,  3.25it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.8399 | Val Loss: 3.7090 | Val Acc: 0.1330 | Top-5: 0.3711 | F1: 0.1140

==== Epoch 17/30 ====
Train: 100%|██████████| 256/256 [02:34<00:00,  1.65it/s]
Val: 100%|██████████| 64/64 [00:36<00:00,  1.76it/s]
Train Loss: 2.8272 | Val Loss: 3.7052 | Val Acc: 0.1340 | Top-5: 0.3790 | F1: 0.1140
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 18/30 ====
Train: 100%|██████████| 256/256 [01:59<00:00,  2.15it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.79it/s]
Train Loss: 2.8203 | Val Loss: 3.6984 | Val Acc: 0.1355 | Top-5: 0.3731 | F1: 0.1156

==== Epoch 19/30 ====
Train: 100%|██████████| 256/256 [01:34<00:00,  2.70it/s]
Val: 100%|██████████| 64/64 [00:14<00:00,  4.35it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.8013 | Val Loss: 3.7007 | Val Acc: 0.1384 | Top-5: 0.3731 | F1: 0.1177

==== Epoch 20/30 ====
Train: 100%|██████████| 256/256 [01:21<00:00,  3.15it/s]
Val: 100%|██████████| 64/64 [00:14<00:00,  4.38it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.7802 | Val Loss: 3.7034 | Val Acc: 0.1325 | Top-5: 0.3756 | F1: 0.1139

==== Epoch 21/30 ====
Train: 100%|██████████| 256/256 [01:17<00:00,  3.30it/s]
Val: 100%|██████████| 64/64 [00:14<00:00,  4.56it/s]
Train Loss: 2.7766 | Val Loss: 3.7071 | Val Acc: 0.1325 | Top-5: 0.3780 | F1: 0.1126

==== Epoch 22/30 ====
Train: 100%|██████████| 256/256 [01:28<00:00,  2.90it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.82it/s]
Train Loss: 2.7584 | Val Loss: 3.6996 | Val Acc: 0.1340 | Top-5: 0.3800 | F1: 0.1160

==== Epoch 23/30 ====
Train: 100%|██████████| 256/256 [01:27<00:00,  2.94it/s]
Val: 100%|██████████| 64/64 [00:17<00:00,  3.74it/s]
Train Loss: 2.7628 | Val Loss: 3.7025 | Val Acc: 0.1369 | Top-5: 0.3775 | F1: 0.1165

==== Epoch 24/30 ====
Train: 100%|██████████| 256/256 [01:23<00:00,  3.05it/s]
Val: 100%|██████████| 64/64 [00:14<00:00,  4.34it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.7520 | Val Loss: 3.7029 | Val Acc: 0.1374 | Top-5: 0.3746 | F1: 0.1183

==== Epoch 25/30 ====
Train: 100%|██████████| 256/256 [01:49<00:00,  2.33it/s]
Val: 100%|██████████| 64/64 [00:22<00:00,  2.85it/s]
Train Loss: 2.7566 | Val Loss: 3.7078 | Val Acc: 0.1359 | Top-5: 0.3809 | F1: 0.1164

==== Epoch 26/30 ====
Train: 100%|██████████| 256/256 [02:52<00:00,  1.48it/s]
Val: 100%|██████████| 64/64 [00:29<00:00,  2.20it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.7489 | Val Loss: 3.7019 | Val Acc: 0.1350 | Top-5: 0.3765 | F1: 0.1136

==== Epoch 27/30 ====
Train: 100%|██████████| 256/256 [01:37<00:00,  2.61it/s]
Val: 100%|██████████| 64/64 [00:15<00:00,  4.22it/s]
Train Loss: 2.7596 | Val Loss: 3.7154 | Val Acc: 0.1399 | Top-5: 0.3716 | F1: 0.1199

==== Epoch 28/30 ====
Train: 100%|██████████| 256/256 [01:26<00:00,  2.97it/s]
Val: 100%|██████████| 64/64 [00:14<00:00,  4.40it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.7565 | Val Loss: 3.7032 | Val Acc: 0.1379 | Top-5: 0.3770 | F1: 0.1172

==== Epoch 29/30 ====
Train: 100%|██████████| 256/256 [01:21<00:00,  3.14it/s]
Val: 100%|██████████| 64/64 [00:14<00:00,  4.30it/s]
Train Loss: 2.7543 | Val Loss: 3.6955 | Val Acc: 0.1276 | Top-5: 0.3780 | F1: 0.1082

==== Epoch 30/30 ====
Train: 100%|██████████| 256/256 [01:22<00:00,  3.12it/s]
Val: 100%|██████████| 64/64 [00:17<00:00,  3.67it/s]
Train Loss: 2.7569 | Val Loss: 3.7136 | Val Acc: 0.1364 | Top-5: 0.3765 | F1: 0.1162
收敛到最优Val Loss Epoch: 29，总训练用时: 55.57 分钟
D:/homework/Course_Design_of_artificial_intelligence/third/ResNet/kaggle_dalao/sam_dalao_before/newV1.py:221: MatplotlibDeprecationWarning: Support for FigureCanvases without a required_interactive_framework attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.
  plt.figure()
D:/homework/Course_Design_of_artificial_intelligence/third/ResNet/kaggle_dalao/sam_dalao_before/newV1.py:231: MatplotlibDeprecationWarning: Support for FigureCanvases without a required_interactive_framework attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.
  plt.figure()
SpeedTest: 100%|██████████| 64/64 [00:15<00:00,  4.11it/s]
推理平均测试速度: 2.144 ms/图像
推理最大显存占用: 418.21 MB
Kaggle Test: 100%|██████████| 324/324 [02:25<00:00,  2.23it/s]
Kaggle提交文件保存至: D:\homework\Course_Design_of_artificial_intelligence\third\ResNet\kaggle_dalao\sam_dalao_before\newV1\submission.csv

进程已结束,退出代码0
