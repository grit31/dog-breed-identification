Downloading: "https://download.pytorch.org/models/resnet50-11ad3fa6.pth" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth
100%|██████████| 97.8M/97.8M [00:00<00:00, 215MB/s]
100%|██████████| 64/64 [01:38<00:00,  1.54s/it]
[Train | 001/050] loss = 4.68848, acc = 0.06909
100%|██████████| 16/16 [00:22<00:00,  1.38s/it]
[ Valid | 001/050 ] loss = 4.55037, acc = 0.22786
100%|██████████| 64/64 [00:48<00:00,  1.31it/s]
[Train | 002/050] loss = 4.41169, acc = 0.25482
100%|██████████| 16/16 [00:09<00:00,  1.62it/s]
[ Valid | 002/050 ] loss = 4.22303, acc = 0.39012
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 003/050] loss = 4.03717, acc = 0.35538
100%|██████████| 16/16 [00:10<00:00,  1.55it/s]
[ Valid | 003/050 ] loss = 3.80582, acc = 0.52035
100%|██████████| 64/64 [00:48<00:00,  1.32it/s]
[Train | 004/050] loss = 3.60135, acc = 0.44253
100%|██████████| 16/16 [00:10<00:00,  1.53it/s]
[ Valid | 004/050 ] loss = 3.31922, acc = 0.61138
100%|██████████| 64/64 [00:48<00:00,  1.31it/s]
[Train | 005/050] loss = 3.14771, acc = 0.51521
100%|██████████| 16/16 [00:10<00:00,  1.55it/s]
[ Valid | 005/050 ] loss = 2.84808, acc = 0.67878
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 006/050] loss = 2.74383, acc = 0.56717
100%|██████████| 16/16 [00:09<00:00,  1.60it/s]
[ Valid | 006/050 ] loss = 2.43171, acc = 0.72413
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 007/050] loss = 2.39352, acc = 0.60918
100%|██████████| 16/16 [00:10<00:00,  1.54it/s]
[ Valid | 007/050 ] loss = 2.06166, acc = 0.75939
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 008/050] loss = 2.12215, acc = 0.64041
100%|██████████| 16/16 [00:09<00:00,  1.63it/s]
[ Valid | 008/050 ] loss = 1.78373, acc = 0.78779
100%|██████████| 64/64 [00:47<00:00,  1.33it/s]
[Train | 009/050] loss = 1.91361, acc = 0.65923
100%|██████████| 16/16 [00:10<00:00,  1.58it/s]
[ Valid | 009/050 ] loss = 1.54683, acc = 0.80343
100%|██████████| 64/64 [00:48<00:00,  1.31it/s]
[Train | 010/050] loss = 1.76161, acc = 0.66757
100%|██████████| 16/16 [00:09<00:00,  1.63it/s]
[ Valid | 010/050 ] loss = 1.37012, acc = 0.81422
100%|██████████| 64/64 [00:49<00:00,  1.29it/s]
[Train | 011/050] loss = 1.63293, acc = 0.67831
100%|██████████| 16/16 [00:10<00:00,  1.51it/s]
[ Valid | 011/050 ] loss = 1.21861, acc = 0.82445
100%|██████████| 64/64 [00:49<00:00,  1.29it/s]
[Train | 012/050] loss = 1.54037, acc = 0.69086
100%|██████████| 16/16 [00:10<00:00,  1.54it/s]
[ Valid | 012/050 ] loss = 1.10817, acc = 0.83474
100%|██████████| 64/64 [00:49<00:00,  1.29it/s]
[Train | 013/050] loss = 1.45519, acc = 0.69600
100%|██████████| 16/16 [00:10<00:00,  1.53it/s]
[ Valid | 013/050 ] loss = 1.00898, acc = 0.84199
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 014/050] loss = 1.38201, acc = 0.70507
100%|██████████| 16/16 [00:10<00:00,  1.53it/s]
[ Valid | 014/050 ] loss = 0.94262, acc = 0.84698
100%|██████████| 64/64 [00:49<00:00,  1.29it/s]
[Train | 015/050] loss = 1.33226, acc = 0.70636
100%|██████████| 16/16 [00:09<00:00,  1.61it/s]
[ Valid | 015/050 ] loss = 0.87388, acc = 0.85332
100%|██████████| 64/64 [00:49<00:00,  1.29it/s]
[Train | 016/050] loss = 1.28653, acc = 0.71163
100%|██████████| 16/16 [00:09<00:00,  1.60it/s]
[ Valid | 016/050 ] loss = 0.82448, acc = 0.85813
100%|██████████| 64/64 [00:48<00:00,  1.31it/s]
[Train | 017/050] loss = 1.27252, acc = 0.70755
100%|██████████| 16/16 [00:10<00:00,  1.56it/s]
[ Valid | 017/050 ] loss = 0.78562, acc = 0.85473
100%|██████████| 64/64 [00:49<00:00,  1.31it/s]
[Train | 018/050] loss = 1.22719, acc = 0.72070
100%|██████████| 16/16 [00:10<00:00,  1.59it/s]
[ Valid | 018/050 ] loss = 0.74166, acc = 0.86408
100%|██████████| 64/64 [00:48<00:00,  1.31it/s]
[Train | 019/050] loss = 1.19990, acc = 0.72493
100%|██████████| 16/16 [00:09<00:00,  1.61it/s]
[ Valid | 019/050 ] loss = 0.71907, acc = 0.85871
100%|██████████| 64/64 [00:48<00:00,  1.31it/s]
[Train | 020/050] loss = 1.15653, acc = 0.73019
100%|██████████| 16/16 [00:10<00:00,  1.53it/s]
[ Valid | 020/050 ] loss = 0.68031, acc = 0.86398
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 021/050] loss = 1.12959, acc = 0.72936
100%|██████████| 16/16 [00:10<00:00,  1.48it/s]
[ Valid | 021/050 ] loss = 0.65411, acc = 0.86255
100%|██████████| 64/64 [00:48<00:00,  1.32it/s]
[Train | 022/050] loss = 1.12166, acc = 0.72897
100%|██████████| 16/16 [00:10<00:00,  1.55it/s]
[ Valid | 022/050 ] loss = 0.64187, acc = 0.86511
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 023/050] loss = 1.09986, acc = 0.73540
100%|██████████| 16/16 [00:10<00:00,  1.59it/s]
[ Valid | 023/050 ] loss = 0.62262, acc = 0.86604
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 024/050] loss = 1.10512, acc = 0.73273
100%|██████████| 16/16 [00:10<00:00,  1.58it/s]
[ Valid | 024/050 ] loss = 0.60340, acc = 0.86601
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 025/050] loss = 1.06719, acc = 0.74219
100%|██████████| 16/16 [00:10<00:00,  1.60it/s]
[ Valid | 025/050 ] loss = 0.59101, acc = 0.86605
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 026/050] loss = 1.06984, acc = 0.73722
100%|██████████| 16/16 [00:10<00:00,  1.59it/s]
[ Valid | 026/050 ] loss = 0.58118, acc = 0.86796
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 027/050] loss = 1.07782, acc = 0.73543
100%|██████████| 16/16 [00:09<00:00,  1.62it/s]
[ Valid | 027/050 ] loss = 0.56484, acc = 0.86943
100%|██████████| 64/64 [00:48<00:00,  1.32it/s]
[Train | 028/050] loss = 1.02328, acc = 0.74562
100%|██████████| 16/16 [00:10<00:00,  1.58it/s]
[ Valid | 028/050 ] loss = 0.55742, acc = 0.87141
100%|██████████| 64/64 [00:48<00:00,  1.31it/s]
[Train | 029/050] loss = 1.01658, acc = 0.74677
100%|██████████| 16/16 [00:10<00:00,  1.58it/s]
[ Valid | 029/050 ] loss = 0.54401, acc = 0.87188
100%|██████████| 64/64 [00:48<00:00,  1.32it/s]
[Train | 030/050] loss = 1.02671, acc = 0.74356
100%|██████████| 16/16 [00:10<00:00,  1.56it/s]
[ Valid | 030/050 ] loss = 0.54220, acc = 0.86994
100%|██████████| 64/64 [00:49<00:00,  1.29it/s]
[Train | 031/050] loss = 1.00921, acc = 0.75327
100%|██████████| 16/16 [00:09<00:00,  1.63it/s]
[ Valid | 031/050 ] loss = 0.53008, acc = 0.87185
100%|██████████| 64/64 [00:48<00:00,  1.31it/s]
[Train | 032/050] loss = 0.98198, acc = 0.75476
100%|██████████| 16/16 [00:09<00:00,  1.63it/s]
[ Valid | 032/050 ] loss = 0.51997, acc = 0.87039
100%|██████████| 64/64 [00:48<00:00,  1.33it/s]
[Train | 033/050] loss = 0.97299, acc = 0.75830
100%|██████████| 16/16 [00:09<00:00,  1.61it/s]
[ Valid | 033/050 ] loss = 0.51442, acc = 0.87093
100%|██████████| 64/64 [00:47<00:00,  1.34it/s]
[Train | 034/050] loss = 0.98187, acc = 0.75266
100%|██████████| 16/16 [00:09<00:00,  1.64it/s]
[ Valid | 034/050 ] loss = 0.51243, acc = 0.87137
100%|██████████| 64/64 [00:48<00:00,  1.32it/s]
[Train | 035/050] loss = 0.99746, acc = 0.74962
100%|██████████| 16/16 [00:10<00:00,  1.54it/s]
[ Valid | 035/050 ] loss = 0.50367, acc = 0.87100
100%|██████████| 64/64 [00:48<00:00,  1.32it/s]
[Train | 036/050] loss = 0.98170, acc = 0.75089
100%|██████████| 16/16 [00:10<00:00,  1.55it/s]
[ Valid | 036/050 ] loss = 0.49347, acc = 0.87927
100%|██████████| 64/64 [00:48<00:00,  1.31it/s]
[Train | 037/050] loss = 0.96955, acc = 0.76103
100%|██████████| 16/16 [00:09<00:00,  1.63it/s]
[ Valid | 037/050 ] loss = 0.49394, acc = 0.87434
100%|██████████| 64/64 [00:48<00:00,  1.32it/s]
[Train | 038/050] loss = 0.96219, acc = 0.75394
100%|██████████| 16/16 [00:09<00:00,  1.61it/s]
[ Valid | 038/050 ] loss = 0.48475, acc = 0.87585
100%|██████████| 64/64 [00:48<00:00,  1.32it/s]
[Train | 039/050] loss = 0.96570, acc = 0.75668
100%|██████████| 16/16 [00:09<00:00,  1.65it/s]
[ Valid | 039/050 ] loss = 0.48814, acc = 0.87141
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 040/050] loss = 0.94419, acc = 0.76476
100%|██████████| 16/16 [00:10<00:00,  1.54it/s]
[ Valid | 040/050 ] loss = 0.47705, acc = 0.87239
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 041/050] loss = 0.93975, acc = 0.75832
100%|██████████| 16/16 [00:10<00:00,  1.57it/s]
[ Valid | 041/050 ] loss = 0.47226, acc = 0.87527
100%|██████████| 64/64 [00:48<00:00,  1.31it/s]
[Train | 042/050] loss = 0.92456, acc = 0.76811
100%|██████████| 16/16 [00:10<00:00,  1.56it/s]
[ Valid | 042/050 ] loss = 0.46680, acc = 0.87629
100%|██████████| 64/64 [00:48<00:00,  1.33it/s]
[Train | 043/050] loss = 0.92477, acc = 0.76690
100%|██████████| 16/16 [00:10<00:00,  1.54it/s]
[ Valid | 043/050 ] loss = 0.46739, acc = 0.87534
100%|██████████| 64/64 [00:47<00:00,  1.34it/s]
[Train | 044/050] loss = 0.91247, acc = 0.77178
100%|██████████| 16/16 [00:10<00:00,  1.57it/s]
[ Valid | 044/050 ] loss = 0.45876, acc = 0.87871
100%|██████████| 64/64 [00:48<00:00,  1.32it/s]
[Train | 045/050] loss = 0.93001, acc = 0.76211
100%|██████████| 16/16 [00:10<00:00,  1.55it/s]
[ Valid | 045/050 ] loss = 0.46121, acc = 0.87631
100%|██████████| 64/64 [00:49<00:00,  1.30it/s]
[Train | 046/050] loss = 0.91431, acc = 0.76299
100%|██████████| 16/16 [00:09<00:00,  1.61it/s]
[ Valid | 046/050 ] loss = 0.45722, acc = 0.87721
100%|██████████| 64/64 [00:49<00:00,  1.29it/s]
[Train | 047/050] loss = 0.92282, acc = 0.76490
100%|██████████| 16/16 [00:10<00:00,  1.57it/s]
[ Valid | 047/050 ] loss = 0.45493, acc = 0.87572
100%|██████████| 64/64 [00:48<00:00,  1.31it/s]
[Train | 048/050] loss = 0.92773, acc = 0.76118
100%|██████████| 16/16 [00:10<00:00,  1.59it/s]
[ Valid | 048/050 ] loss = 0.44830, acc = 0.87665
100%|██████████| 64/64 [00:48<00:00,  1.32it/s]
[Train | 049/050] loss = 0.90354, acc = 0.77220
100%|██████████| 16/16 [00:10<00:00,  1.55it/s]
[ Valid | 049/050 ] loss = 0.44879, acc = 0.87634
100%|██████████| 64/64 [00:48<00:00,  1.31it/s]
[Train | 050/050] loss = 0.89288, acc = 0.77041
100%|██████████| 16/16 [00:10<00:00,  1.52it/s]
[ Valid | 050/050 ] loss = 0.44979, acc = 0.87582
模型保存成功，目录为：/kaggle/working/pre_res_model.ckpt


print(total_train_loss)
print(total_train_accs)
print(total_valid_loss)
print(total_valid_accs)


[4.688478946685791, 4.411685466766357, 4.037172317504883, 3.6013457775115967, 3.147714853286743, 2.7438337802886963, 2.393523931503296, 2.1221511363983154, 1.9136123657226562, 1.7616114616394043, 1.632934808731079, 1.540373682975769, 1.4551938772201538, 1.382009744644165, 1.33226478099823, 1.2865312099456787, 1.2725197076797485, 1.2271897792816162, 1.1998995542526245, 1.156532645225525, 1.12958562374115, 1.1216564178466797, 1.0998603105545044, 1.1051199436187744, 1.0671892166137695, 1.0698446035385132, 1.0778183937072754, 1.0232826471328735, 1.016579508781433, 1.0267093181610107, 1.009211540222168, 0.9819755554199219, 0.9729927778244019, 0.9818677306175232, 0.997458279132843, 0.9817032217979431, 0.9695466756820679, 0.9621910452842712, 0.9657018780708313, 0.9441934823989868, 0.9397478699684143, 0.9245639443397522, 0.9247691631317139, 0.9124666452407837, 0.9300065040588379, 0.9143149256706238, 0.9228204488754272, 0.927727997303009, 0.9035447239875793, 0.8928765654563904]
[0.06909071654081345, 0.25482338666915894, 0.35537585616111755, 0.4425254166126251, 0.5152145028114319, 0.5671667456626892, 0.6091827154159546, 0.6404078602790833, 0.6592315435409546, 0.6675723195075989, 0.6783069372177124, 0.6908553242683411, 0.69599848985672, 0.7050727009773254, 0.7063582539558411, 0.7116310596466064, 0.7075465321540833, 0.7206977009773254, 0.72492915391922, 0.7301943898200989, 0.7293646931648254, 0.7289736866950989, 0.7354023456573486, 0.7327254414558411, 0.7421896457672119, 0.7372171878814697, 0.73542720079422, 0.7456238269805908, 0.7467710971832275, 0.7435648441314697, 0.7532731890678406, 0.7547553181648254, 0.7583029270172119, 0.7526553273200989, 0.749619722366333, 0.7508890628814697, 0.7610284686088562, 0.7539408206939697, 0.7566750049591064, 0.7647640109062195, 0.7583191394805908, 0.7681085467338562, 0.7668964862823486, 0.7717792987823486, 0.7621108889579773, 0.7629902362823486, 0.7649022936820984, 0.7611753940582275, 0.772202730178833, 0.7704116702079773]
[4.550370216369629, 4.223031520843506, 3.8058156967163086, 3.319221258163452, 2.848076343536377, 2.431709051132202, 2.0616610050201416, 1.7837276458740234, 1.5468273162841797, 1.3701189756393433, 1.218606948852539, 1.1081722974777222, 1.0089794397354126, 0.9426244497299194, 0.8738794326782227, 0.8244785666465759, 0.7856159210205078, 0.741657018661499, 0.7190717458724976, 0.6803101897239685, 0.6541138291358948, 0.6418703198432922, 0.6226173639297485, 0.6033962368965149, 0.5910083651542664, 0.5811833143234253, 0.5648435950279236, 0.5574206709861755, 0.5440118312835693, 0.542203426361084, 0.5300828814506531, 0.5199719071388245, 0.5144156813621521, 0.5124307870864868, 0.5036716461181641, 0.4934663474559784, 0.49394306540489197, 0.48475411534309387, 0.4881443381309509, 0.47704893350601196, 0.4722558557987213, 0.46679750084877014, 0.4673858880996704, 0.45875927805900574, 0.4612088203430176, 0.4572174847126007, 0.4549298584461212, 0.4483049213886261, 0.44878941774368286, 0.44978612661361694]
[0.22785547375679016, 0.39011719822883606, 0.5203515887260437, 0.6113828420639038, 0.6787773370742798, 0.7241289019584656, 0.759390652179718, 0.787792980670929, 0.8034296631813049, 0.8142187595367432, 0.8244492411613464, 0.8347382545471191, 0.841992199420929, 0.8469804525375366, 0.8533164262771606, 0.8581289052963257, 0.8547343611717224, 0.8640820384025574, 0.8587109446525574, 0.8639765381813049, 0.8625468611717224, 0.8651054501533508, 0.8660351634025574, 0.8660117387771606, 0.8660469055175781, 0.8679648637771606, 0.8694297075271606, 0.8714062571525574, 0.8718827962875366, 0.8699414134025574, 0.8718476295471191, 0.8703945279121399, 0.8709297180175781, 0.8713710904121399, 0.8709999918937683, 0.8792656064033508, 0.8743359446525574, 0.8758476376533508, 0.8714062571525574, 0.8723945617675781, 0.8752655982971191, 0.8762890696525574, 0.8753359317779541, 0.8787070512771606, 0.8763124942779541, 0.8772070407867432, 0.8757187724113464, 0.8766484260559082, 0.8763359189033508, 0.8758242130279541]