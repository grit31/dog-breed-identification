20250524
正在跑
adam lr =0.001
D:\ProgramData\anaconda3\envs\homework_2_1\python.exe D:/homework/Course_Design_of_artificial_intelligence/third/ResNet_Seblock/fangzhang_ResNet_kaggle_dalao/sam_dalao_before_seblock/newV1.py
Using device: cuda
数据增强：关闭 | 训练：True | 测试：True
------ 模型结构和参数量 ------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
            Conv2d-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
              ReLU-7           [-1, 64, 56, 56]               0
            Conv2d-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
AdaptiveAvgPool2d-10             [-1, 64, 1, 1]               0
           Linear-11                    [-1, 4]             256
             ReLU-12                    [-1, 4]               0
           Linear-13                   [-1, 64]             256
          Sigmoid-14                   [-1, 64]               0
          SEBlock-15           [-1, 64, 56, 56]               0
             ReLU-16           [-1, 64, 56, 56]               0
     BasicBlockSE-17           [-1, 64, 56, 56]               0
           Conv2d-18           [-1, 64, 56, 56]          36,864
      BatchNorm2d-19           [-1, 64, 56, 56]             128
             ReLU-20           [-1, 64, 56, 56]               0
           Conv2d-21           [-1, 64, 56, 56]          36,864
      BatchNorm2d-22           [-1, 64, 56, 56]             128
AdaptiveAvgPool2d-23             [-1, 64, 1, 1]               0
           Linear-24                    [-1, 4]             256
             ReLU-25                    [-1, 4]               0
           Linear-26                   [-1, 64]             256
          Sigmoid-27                   [-1, 64]               0
          SEBlock-28           [-1, 64, 56, 56]               0
             ReLU-29           [-1, 64, 56, 56]               0
     BasicBlockSE-30           [-1, 64, 56, 56]               0
           Conv2d-31          [-1, 128, 28, 28]          73,728
      BatchNorm2d-32          [-1, 128, 28, 28]             256
             ReLU-33          [-1, 128, 28, 28]               0
           Conv2d-34          [-1, 128, 28, 28]         147,456
      BatchNorm2d-35          [-1, 128, 28, 28]             256
AdaptiveAvgPool2d-36            [-1, 128, 1, 1]               0
           Linear-37                    [-1, 8]           1,024
             ReLU-38                    [-1, 8]               0
           Linear-39                  [-1, 128]           1,024
          Sigmoid-40                  [-1, 128]               0
          SEBlock-41          [-1, 128, 28, 28]               0
           Conv2d-42          [-1, 128, 28, 28]           8,192
      BatchNorm2d-43          [-1, 128, 28, 28]             256
             ReLU-44          [-1, 128, 28, 28]               0
     BasicBlockSE-45          [-1, 128, 28, 28]               0
           Conv2d-46          [-1, 128, 28, 28]         147,456
      BatchNorm2d-47          [-1, 128, 28, 28]             256
             ReLU-48          [-1, 128, 28, 28]               0
           Conv2d-49          [-1, 128, 28, 28]         147,456
      BatchNorm2d-50          [-1, 128, 28, 28]             256
AdaptiveAvgPool2d-51            [-1, 128, 1, 1]               0
           Linear-52                    [-1, 8]           1,024
             ReLU-53                    [-1, 8]               0
           Linear-54                  [-1, 128]           1,024
          Sigmoid-55                  [-1, 128]               0
          SEBlock-56          [-1, 128, 28, 28]               0
             ReLU-57          [-1, 128, 28, 28]               0
     BasicBlockSE-58          [-1, 128, 28, 28]               0
           Conv2d-59          [-1, 256, 14, 14]         294,912
      BatchNorm2d-60          [-1, 256, 14, 14]             512
             ReLU-61          [-1, 256, 14, 14]               0
           Conv2d-62          [-1, 256, 14, 14]         589,824
      BatchNorm2d-63          [-1, 256, 14, 14]             512
AdaptiveAvgPool2d-64            [-1, 256, 1, 1]               0
           Linear-65                   [-1, 16]           4,096
             ReLU-66                   [-1, 16]               0
           Linear-67                  [-1, 256]           4,096
          Sigmoid-68                  [-1, 256]               0
          SEBlock-69          [-1, 256, 14, 14]               0
           Conv2d-70          [-1, 256, 14, 14]          32,768
      BatchNorm2d-71          [-1, 256, 14, 14]             512
             ReLU-72          [-1, 256, 14, 14]               0
     BasicBlockSE-73          [-1, 256, 14, 14]               0
           Conv2d-74          [-1, 256, 14, 14]         589,824
      BatchNorm2d-75          [-1, 256, 14, 14]             512
             ReLU-76          [-1, 256, 14, 14]               0
           Conv2d-77          [-1, 256, 14, 14]         589,824
      BatchNorm2d-78          [-1, 256, 14, 14]             512
AdaptiveAvgPool2d-79            [-1, 256, 1, 1]               0
           Linear-80                   [-1, 16]           4,096
             ReLU-81                   [-1, 16]               0
           Linear-82                  [-1, 256]           4,096
          Sigmoid-83                  [-1, 256]               0
          SEBlock-84          [-1, 256, 14, 14]               0
             ReLU-85          [-1, 256, 14, 14]               0
     BasicBlockSE-86          [-1, 256, 14, 14]               0
           Conv2d-87            [-1, 512, 7, 7]       1,179,648
      BatchNorm2d-88            [-1, 512, 7, 7]           1,024
             ReLU-89            [-1, 512, 7, 7]               0
           Conv2d-90            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-91            [-1, 512, 7, 7]           1,024
AdaptiveAvgPool2d-92            [-1, 512, 1, 1]               0
           Linear-93                   [-1, 32]          16,384
             ReLU-94                   [-1, 32]               0
           Linear-95                  [-1, 512]          16,384
          Sigmoid-96                  [-1, 512]               0
          SEBlock-97            [-1, 512, 7, 7]               0
           Conv2d-98            [-1, 512, 7, 7]         131,072
      BatchNorm2d-99            [-1, 512, 7, 7]           1,024
            ReLU-100            [-1, 512, 7, 7]               0
    BasicBlockSE-101            [-1, 512, 7, 7]               0
          Conv2d-102            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-103            [-1, 512, 7, 7]           1,024
            ReLU-104            [-1, 512, 7, 7]               0
          Conv2d-105            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-106            [-1, 512, 7, 7]           1,024
AdaptiveAvgPool2d-107            [-1, 512, 1, 1]               0
          Linear-108                   [-1, 32]          16,384
            ReLU-109                   [-1, 32]               0
          Linear-110                  [-1, 512]          16,384
         Sigmoid-111                  [-1, 512]               0
         SEBlock-112            [-1, 512, 7, 7]               0
            ReLU-113            [-1, 512, 7, 7]               0
    BasicBlockSE-114            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-115            [-1, 512, 1, 1]               0
          Linear-116                  [-1, 120]          61,560
================================================================
Total params: 11,325,112
Trainable params: 11,325,112
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 68.57
Params size (MB): 43.20
Estimated Total Size (MB): 112.35
----------------------------------------------------------------
参数量: 11.33M
模型大小: 43.24 MB
FLOPs: 3.65 GFLOPs/图像

==== Epoch 1/30 ====
Train: 100%|██████████| 256/256 [01:24<00:00,  3.03it/s]
Val: 100%|██████████| 64/64 [00:14<00:00,  4.40it/s]
Train Loss: 4.7535 | Val Loss: 4.6577 | Val Acc: 0.0254 | Top-5: 0.1076 | F1: 0.0047
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 2/30 ====
Train: 100%|██████████| 256/256 [01:22<00:00,  3.11it/s]
Val: 100%|██████████| 64/64 [00:14<00:00,  4.41it/s]
Train Loss: 4.4893 | Val Loss: 4.4159 | Val Acc: 0.0406 | Top-5: 0.1462 | F1: 0.0102

==== Epoch 3/30 ====
Train: 100%|██████████| 256/256 [01:21<00:00,  3.14it/s]
Val: 100%|██████████| 64/64 [00:14<00:00,  4.55it/s]
Train Loss: 4.2787 | Val Loss: 4.2753 | Val Acc: 0.0513 | Top-5: 0.1951 | F1: 0.0210
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 4/30 ====
Train: 100%|██████████| 256/256 [01:20<00:00,  3.19it/s]
Val: 100%|██████████| 64/64 [00:13<00:00,  4.58it/s]
Train Loss: 4.1206 | Val Loss: 4.1610 | Val Acc: 0.0645 | Top-5: 0.2220 | F1: 0.0309
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 5/30 ====
Train: 100%|██████████| 256/256 [01:22<00:00,  3.12it/s]
Val: 100%|██████████| 64/64 [00:14<00:00,  4.52it/s]
Train Loss: 3.9539 | Val Loss: 4.1508 | Val Acc: 0.0616 | Top-5: 0.2303 | F1: 0.0391
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 6/30 ====
Train: 100%|██████████| 256/256 [01:21<00:00,  3.14it/s]
Val: 100%|██████████| 64/64 [00:14<00:00,  4.50it/s]
Train Loss: 3.8243 | Val Loss: 4.0152 | Val Acc: 0.0856 | Top-5: 0.2900 | F1: 0.0569
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 7/30 ====
Train: 100%|██████████| 256/256 [01:26<00:00,  2.97it/s]
Val: 100%|██████████| 64/64 [00:15<00:00,  4.02it/s]
Train Loss: 3.6600 | Val Loss: 3.8734 | Val Acc: 0.1032 | Top-5: 0.3237 | F1: 0.0690
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 8/30 ====
Train: 100%|██████████| 256/256 [01:30<00:00,  2.82it/s]
Val: 100%|██████████| 64/64 [00:15<00:00,  4.08it/s]
Train Loss: 3.3019 | Val Loss: 3.6615 | Val Acc: 0.1237 | Top-5: 0.3746 | F1: 0.0958
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 9/30 ====
Train: 100%|██████████| 256/256 [01:36<00:00,  2.65it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.97it/s]
Train Loss: 3.1752 | Val Loss: 3.6435 | Val Acc: 0.1267 | Top-5: 0.3780 | F1: 0.1010

==== Epoch 10/30 ====
Train: 100%|██████████| 256/256 [01:32<00:00,  2.76it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.82it/s]
Train Loss: 3.0860 | Val Loss: 3.6054 | Val Acc: 0.1408 | Top-5: 0.3941 | F1: 0.1148
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 11/30 ====
Train: 100%|██████████| 256/256 [01:35<00:00,  2.69it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.82it/s]
Train Loss: 3.0134 | Val Loss: 3.6015 | Val Acc: 0.1438 | Top-5: 0.3883 | F1: 0.1178

==== Epoch 12/30 ====
Train: 100%|██████████| 256/256 [01:32<00:00,  2.76it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.79it/s]
Train Loss: 2.9461 | Val Loss: 3.5896 | Val Acc: 0.1457 | Top-5: 0.4049 | F1: 0.1227

==== Epoch 13/30 ====
Train: 100%|██████████| 256/256 [01:32<00:00,  2.76it/s]
Val: 100%|██████████| 64/64 [00:17<00:00,  3.60it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.8687 | Val Loss: 3.6006 | Val Acc: 0.1526 | Top-5: 0.3966 | F1: 0.1297

==== Epoch 14/30 ====
Train: 100%|██████████| 256/256 [01:34<00:00,  2.70it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.87it/s]
Train Loss: 2.7832 | Val Loss: 3.5778 | Val Acc: 0.1560 | Top-5: 0.4117 | F1: 0.1340

==== Epoch 15/30 ====
Train: 100%|██████████| 256/256 [01:33<00:00,  2.74it/s]
Val: 100%|██████████| 64/64 [00:17<00:00,  3.73it/s]
Train Loss: 2.6744 | Val Loss: 3.5661 | Val Acc: 0.1555 | Top-5: 0.4196 | F1: 0.1341
Train:   0%|          | 0/256 [00:00<?, ?it/s]
==== Epoch 16/30 ====
Train: 100%|██████████| 256/256 [02:00<00:00,  2.13it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.83it/s]
Train Loss: 2.6539 | Val Loss: 3.5659 | Val Acc: 0.1594 | Top-5: 0.4112 | F1: 0.1376

==== Epoch 17/30 ====
Train: 100%|██████████| 256/256 [01:32<00:00,  2.76it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.87it/s]
Train Loss: 2.6473 | Val Loss: 3.5721 | Val Acc: 0.1584 | Top-5: 0.4176 | F1: 0.1344

==== Epoch 18/30 ====
Train: 100%|██████████| 256/256 [01:36<00:00,  2.65it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.88it/s]
Train Loss: 2.6300 | Val Loss: 3.5745 | Val Acc: 0.1550 | Top-5: 0.4142 | F1: 0.1356

==== Epoch 19/30 ====
Train: 100%|██████████| 256/256 [01:34<00:00,  2.72it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.89it/s]
Train Loss: 2.6297 | Val Loss: 3.5706 | Val Acc: 0.1614 | Top-5: 0.4171 | F1: 0.1394

==== Epoch 20/30 ====
Train: 100%|██████████| 256/256 [01:28<00:00,  2.88it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.94it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.6110 | Val Loss: 3.5713 | Val Acc: 0.1545 | Top-5: 0.4171 | F1: 0.1349

==== Epoch 21/30 ====
Train: 100%|██████████| 256/256 [01:28<00:00,  2.91it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.97it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.6115 | Val Loss: 3.5744 | Val Acc: 0.1614 | Top-5: 0.4142 | F1: 0.1403

==== Epoch 22/30 ====
Train: 100%|██████████| 256/256 [01:28<00:00,  2.90it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  4.00it/s]
Train Loss: 2.5961 | Val Loss: 3.5753 | Val Acc: 0.1589 | Top-5: 0.4191 | F1: 0.1371

==== Epoch 23/30 ====
Train: 100%|██████████| 256/256 [01:28<00:00,  2.89it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.96it/s]
Train Loss: 2.5906 | Val Loss: 3.5687 | Val Acc: 0.1589 | Top-5: 0.4191 | F1: 0.1380

==== Epoch 24/30 ====
Train: 100%|██████████| 256/256 [01:29<00:00,  2.85it/s]
Val: 100%|██████████| 64/64 [00:15<00:00,  4.01it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.5932 | Val Loss: 3.5789 | Val Acc: 0.1491 | Top-5: 0.4156 | F1: 0.1283

==== Epoch 25/30 ====
Train: 100%|██████████| 256/256 [01:29<00:00,  2.87it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.99it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.5865 | Val Loss: 3.5711 | Val Acc: 0.1555 | Top-5: 0.4137 | F1: 0.1346

==== Epoch 26/30 ====
Train: 100%|██████████| 256/256 [01:30<00:00,  2.82it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.85it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.5766 | Val Loss: 3.5741 | Val Acc: 0.1575 | Top-5: 0.4127 | F1: 0.1365

==== Epoch 27/30 ====
Train: 100%|██████████| 256/256 [01:33<00:00,  2.73it/s]
Val: 100%|██████████| 64/64 [00:17<00:00,  3.72it/s]
Train Loss: 2.5880 | Val Loss: 3.5877 | Val Acc: 0.1535 | Top-5: 0.4112 | F1: 0.1346

==== Epoch 28/30 ====
Train: 100%|██████████| 256/256 [01:38<00:00,  2.61it/s]
Val: 100%|██████████| 64/64 [00:15<00:00,  4.03it/s]
Train Loss: 2.5870 | Val Loss: 3.5743 | Val Acc: 0.1555 | Top-5: 0.4166 | F1: 0.1346

==== Epoch 29/30 ====
Train: 100%|██████████| 256/256 [01:32<00:00,  2.77it/s]
Val: 100%|██████████| 64/64 [00:15<00:00,  4.09it/s]
Train:   0%|          | 0/256 [00:00<?, ?it/s]Train Loss: 2.5885 | Val Loss: 3.5740 | Val Acc: 0.1565 | Top-5: 0.4152 | F1: 0.1374

==== Epoch 30/30 ====
Train: 100%|██████████| 256/256 [01:32<00:00,  2.78it/s]
Val: 100%|██████████| 64/64 [00:16<00:00,  3.87it/s]
Train Loss: 2.5866 | Val Loss: 3.5715 | Val Acc: 0.1589 | Top-5: 0.4171 | F1: 0.1387
收敛到最优Val Loss Epoch: 16，总训练用时: 53.55 分钟
D:/homework/Course_Design_of_artificial_intelligence/third/ResNet_Seblock/fangzhang_ResNet_kaggle_dalao/sam_dalao_before_seblock/newV1.py:256: MatplotlibDeprecationWarning: Support for FigureCanvases without a required_interactive_framework attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.
  plt.figure()
D:/homework/Course_Design_of_artificial_intelligence/third/ResNet_Seblock/fangzhang_ResNet_kaggle_dalao/sam_dalao_before_seblock/newV1.py:266: MatplotlibDeprecationWarning: Support for FigureCanvases without a required_interactive_framework attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.
  plt.figure()
SpeedTest: 100%|██████████| 64/64 [00:17<00:00,  3.70it/s]
推理平均测试速度: 1.927 ms/图像
推理最大显存占用: 421.23 MB
Kaggle Test: 100%|██████████| 324/324 [02:36<00:00,  2.07it/s]
Kaggle提交文件保存至: D:\homework\Course_Design_of_artificial_intelligence\third\ResNet_Seblock\fangzhang_ResNet_kaggle_dalao\sam_dalao_before_seblock\newV1\submission_se.csv

进程已结束,退出代码0



20250524 sgd=0.01
