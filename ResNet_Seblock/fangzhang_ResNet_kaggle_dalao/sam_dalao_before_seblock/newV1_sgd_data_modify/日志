lr = 0.001
epochs =50
batch =64


D:\ProgramData\anaconda3\envs\homework_2_1\python.exe D:/homework/Course_Design_of_artificial_intelligence/third/ResNet_Seblock/fangzhang_ResNet_kaggle_dalao/sam_dalao_before_seblock/newV1_data.py
Using device: cuda
数据增强：True | 训练：True | 测试：True
数据增强
------ 模型结构和参数量 ------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
            Conv2d-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
              ReLU-7           [-1, 64, 56, 56]               0
            Conv2d-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
AdaptiveAvgPool2d-10             [-1, 64, 1, 1]               0
           Linear-11                    [-1, 4]             256
             ReLU-12                    [-1, 4]               0
           Linear-13                   [-1, 64]             256
          Sigmoid-14                   [-1, 64]               0
          SEBlock-15           [-1, 64, 56, 56]               0
             ReLU-16           [-1, 64, 56, 56]               0
     BasicBlockSE-17           [-1, 64, 56, 56]               0
           Conv2d-18           [-1, 64, 56, 56]          36,864
      BatchNorm2d-19           [-1, 64, 56, 56]             128
             ReLU-20           [-1, 64, 56, 56]               0
           Conv2d-21           [-1, 64, 56, 56]          36,864
      BatchNorm2d-22           [-1, 64, 56, 56]             128
AdaptiveAvgPool2d-23             [-1, 64, 1, 1]               0
           Linear-24                    [-1, 4]             256
             ReLU-25                    [-1, 4]               0
           Linear-26                   [-1, 64]             256
          Sigmoid-27                   [-1, 64]               0
          SEBlock-28           [-1, 64, 56, 56]               0
             ReLU-29           [-1, 64, 56, 56]               0
     BasicBlockSE-30           [-1, 64, 56, 56]               0
           Conv2d-31          [-1, 128, 28, 28]          73,728
      BatchNorm2d-32          [-1, 128, 28, 28]             256
             ReLU-33          [-1, 128, 28, 28]               0
           Conv2d-34          [-1, 128, 28, 28]         147,456
      BatchNorm2d-35          [-1, 128, 28, 28]             256
AdaptiveAvgPool2d-36            [-1, 128, 1, 1]               0
           Linear-37                    [-1, 8]           1,024
             ReLU-38                    [-1, 8]               0
           Linear-39                  [-1, 128]           1,024
          Sigmoid-40                  [-1, 128]               0
          SEBlock-41          [-1, 128, 28, 28]               0
           Conv2d-42          [-1, 128, 28, 28]           8,192
      BatchNorm2d-43          [-1, 128, 28, 28]             256
             ReLU-44          [-1, 128, 28, 28]               0
     BasicBlockSE-45          [-1, 128, 28, 28]               0
           Conv2d-46          [-1, 128, 28, 28]         147,456
      BatchNorm2d-47          [-1, 128, 28, 28]             256
             ReLU-48          [-1, 128, 28, 28]               0
           Conv2d-49          [-1, 128, 28, 28]         147,456
      BatchNorm2d-50          [-1, 128, 28, 28]             256
AdaptiveAvgPool2d-51            [-1, 128, 1, 1]               0
           Linear-52                    [-1, 8]           1,024
             ReLU-53                    [-1, 8]               0
           Linear-54                  [-1, 128]           1,024
          Sigmoid-55                  [-1, 128]               0
          SEBlock-56          [-1, 128, 28, 28]               0
             ReLU-57          [-1, 128, 28, 28]               0
     BasicBlockSE-58          [-1, 128, 28, 28]               0
           Conv2d-59          [-1, 256, 14, 14]         294,912
      BatchNorm2d-60          [-1, 256, 14, 14]             512
             ReLU-61          [-1, 256, 14, 14]               0
           Conv2d-62          [-1, 256, 14, 14]         589,824
      BatchNorm2d-63          [-1, 256, 14, 14]             512
AdaptiveAvgPool2d-64            [-1, 256, 1, 1]               0
           Linear-65                   [-1, 16]           4,096
             ReLU-66                   [-1, 16]               0
           Linear-67                  [-1, 256]           4,096
          Sigmoid-68                  [-1, 256]               0
          SEBlock-69          [-1, 256, 14, 14]               0
           Conv2d-70          [-1, 256, 14, 14]          32,768
      BatchNorm2d-71          [-1, 256, 14, 14]             512
             ReLU-72          [-1, 256, 14, 14]               0
     BasicBlockSE-73          [-1, 256, 14, 14]               0
           Conv2d-74          [-1, 256, 14, 14]         589,824
      BatchNorm2d-75          [-1, 256, 14, 14]             512
             ReLU-76          [-1, 256, 14, 14]               0
           Conv2d-77          [-1, 256, 14, 14]         589,824
      BatchNorm2d-78          [-1, 256, 14, 14]             512
AdaptiveAvgPool2d-79            [-1, 256, 1, 1]               0
           Linear-80                   [-1, 16]           4,096
             ReLU-81                   [-1, 16]               0
           Linear-82                  [-1, 256]           4,096
          Sigmoid-83                  [-1, 256]               0
          SEBlock-84          [-1, 256, 14, 14]               0
             ReLU-85          [-1, 256, 14, 14]               0
     BasicBlockSE-86          [-1, 256, 14, 14]               0
           Conv2d-87            [-1, 512, 7, 7]       1,179,648
      BatchNorm2d-88            [-1, 512, 7, 7]           1,024
             ReLU-89            [-1, 512, 7, 7]               0
           Conv2d-90            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-91            [-1, 512, 7, 7]           1,024
AdaptiveAvgPool2d-92            [-1, 512, 1, 1]               0
           Linear-93                   [-1, 32]          16,384
             ReLU-94                   [-1, 32]               0
           Linear-95                  [-1, 512]          16,384
          Sigmoid-96                  [-1, 512]               0
          SEBlock-97            [-1, 512, 7, 7]               0
           Conv2d-98            [-1, 512, 7, 7]         131,072
      BatchNorm2d-99            [-1, 512, 7, 7]           1,024
            ReLU-100            [-1, 512, 7, 7]               0
    BasicBlockSE-101            [-1, 512, 7, 7]               0
          Conv2d-102            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-103            [-1, 512, 7, 7]           1,024
            ReLU-104            [-1, 512, 7, 7]               0
          Conv2d-105            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-106            [-1, 512, 7, 7]           1,024
AdaptiveAvgPool2d-107            [-1, 512, 1, 1]               0
          Linear-108                   [-1, 32]          16,384
            ReLU-109                   [-1, 32]               0
          Linear-110                  [-1, 512]          16,384
         Sigmoid-111                  [-1, 512]               0
         SEBlock-112            [-1, 512, 7, 7]               0
            ReLU-113            [-1, 512, 7, 7]               0
    BasicBlockSE-114            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-115            [-1, 512, 1, 1]               0
          Linear-116                  [-1, 120]          61,560
================================================================
Total params: 11,325,112
Trainable params: 11,325,112
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 68.57
Params size (MB): 43.20
Estimated Total Size (MB): 112.35
----------------------------------------------------------------
参数量: 11.33M
模型大小: 43.24 MB
Train:   0%|          | 0/128 [00:00<?, ?it/s]FLOPs: 3.65 GFLOPs/图像

==== Epoch 1/50 ====
Train: 100%|██████████| 128/128 [02:35<00:00,  1.21s/it]
Val: 100%|██████████| 32/32 [00:24<00:00,  1.31it/s]
Train Loss: 4.7876 | Val Loss: 4.7694 | Val Acc: 0.0161 | Top-5: 0.0567 | F1: 0.0018
Train:   0%|          | 0/128 [00:00<?, ?it/s]
==== Epoch 2/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.68it/s]
Train Loss: 4.7716 | Val Loss: 4.7600 | Val Acc: 0.0196 | Top-5: 0.0724 | F1: 0.0028
Train:   0%|          | 0/128 [00:00<?, ?it/s]
==== Epoch 3/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train Loss: 4.7583 | Val Loss: 4.7468 | Val Acc: 0.0240 | Top-5: 0.0822 | F1: 0.0026
Train:   0%|          | 0/128 [00:00<?, ?it/s]
==== Epoch 4/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train Loss: 4.7409 | Val Loss: 4.7313 | Val Acc: 0.0264 | Top-5: 0.0973 | F1: 0.0032

==== Epoch 5/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train Loss: 4.7191 | Val Loss: 4.7122 | Val Acc: 0.0254 | Top-5: 0.1037 | F1: 0.0024
Train:   0%|          | 0/128 [00:00<?, ?it/s]
==== Epoch 6/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.69it/s]
Train Loss: 4.6913 | Val Loss: 4.6878 | Val Acc: 0.0240 | Top-5: 0.1095 | F1: 0.0042
Train:   0%|          | 0/128 [00:00<?, ?it/s]
==== Epoch 7/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.70it/s]
Train Loss: 4.6608 | Val Loss: 4.6619 | Val Acc: 0.0337 | Top-5: 0.1125 | F1: 0.0076

==== Epoch 8/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train Loss: 4.6331 | Val Loss: 4.6577 | Val Acc: 0.0333 | Top-5: 0.1164 | F1: 0.0077

==== Epoch 9/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train Loss: 4.6302 | Val Loss: 4.6551 | Val Acc: 0.0342 | Top-5: 0.1164 | F1: 0.0087

==== Epoch 10/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.69it/s]
Train Loss: 4.6268 | Val Loss: 4.6512 | Val Acc: 0.0313 | Top-5: 0.1169 | F1: 0.0077

==== Epoch 11/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.69it/s]
Train Loss: 4.6226 | Val Loss: 4.6488 | Val Acc: 0.0333 | Top-5: 0.1188 | F1: 0.0078
Train:   0%|          | 0/128 [00:00<?, ?it/s]
==== Epoch 12/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.73it/s]
Train Loss: 4.6183 | Val Loss: 4.6459 | Val Acc: 0.0333 | Top-5: 0.1242 | F1: 0.0075

==== Epoch 13/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.71it/s]
Train Loss: 4.6153 | Val Loss: 4.6453 | Val Acc: 0.0328 | Top-5: 0.1276 | F1: 0.0081
Train:   0%|          | 0/128 [00:00<?, ?it/s]
==== Epoch 14/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.32it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.71it/s]
Train Loss: 4.6102 | Val Loss: 4.6410 | Val Acc: 0.0333 | Top-5: 0.1252 | F1: 0.0073

==== Epoch 15/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train Loss: 4.6086 | Val Loss: 4.6406 | Val Acc: 0.0337 | Top-5: 0.1242 | F1: 0.0074

==== Epoch 16/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.73it/s]
Train Loss: 4.6093 | Val Loss: 4.6399 | Val Acc: 0.0323 | Top-5: 0.1257 | F1: 0.0070

==== Epoch 17/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train Loss: 4.6087 | Val Loss: 4.6395 | Val Acc: 0.0337 | Top-5: 0.1276 | F1: 0.0074
Train:   0%|          | 0/128 [00:00<?, ?it/s]
==== Epoch 18/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.69it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6054 | Val Loss: 4.6404 | Val Acc: 0.0337 | Top-5: 0.1286 | F1: 0.0074

==== Epoch 19/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6084 | Val Loss: 4.6409 | Val Acc: 0.0333 | Top-5: 0.1252 | F1: 0.0083

==== Epoch 20/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train Loss: 4.6068 | Val Loss: 4.6391 | Val Acc: 0.0328 | Top-5: 0.1242 | F1: 0.0068

==== Epoch 21/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.68it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6070 | Val Loss: 4.6394 | Val Acc: 0.0352 | Top-5: 0.1267 | F1: 0.0084

==== Epoch 22/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6062 | Val Loss: 4.6395 | Val Acc: 0.0352 | Top-5: 0.1267 | F1: 0.0091

==== Epoch 23/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6049 | Val Loss: 4.6395 | Val Acc: 0.0342 | Top-5: 0.1262 | F1: 0.0079

==== Epoch 24/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.71it/s]
Train Loss: 4.6086 | Val Loss: 4.6386 | Val Acc: 0.0323 | Top-5: 0.1257 | F1: 0.0069
Train:   0%|          | 0/128 [00:00<?, ?it/s]
==== Epoch 25/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.70it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6058 | Val Loss: 4.6404 | Val Acc: 0.0328 | Top-5: 0.1276 | F1: 0.0081

==== Epoch 26/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6059 | Val Loss: 4.6395 | Val Acc: 0.0328 | Top-5: 0.1257 | F1: 0.0086

==== Epoch 27/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.70it/s]
Train Loss: 4.6064 | Val Loss: 4.6389 | Val Acc: 0.0342 | Top-5: 0.1267 | F1: 0.0076

==== Epoch 28/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train Loss: 4.6050 | Val Loss: 4.6399 | Val Acc: 0.0328 | Top-5: 0.1247 | F1: 0.0078

==== Epoch 29/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.68it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6046 | Val Loss: 4.6400 | Val Acc: 0.0337 | Top-5: 0.1276 | F1: 0.0090

==== Epoch 30/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6042 | Val Loss: 4.6396 | Val Acc: 0.0342 | Top-5: 0.1267 | F1: 0.0090

==== Epoch 31/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.73it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6053 | Val Loss: 4.6393 | Val Acc: 0.0342 | Top-5: 0.1267 | F1: 0.0082

==== Epoch 32/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:12<00:00,  2.66it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6064 | Val Loss: 4.6391 | Val Acc: 0.0337 | Top-5: 0.1257 | F1: 0.0076

==== Epoch 33/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train Loss: 4.6038 | Val Loss: 4.6402 | Val Acc: 0.0357 | Top-5: 0.1276 | F1: 0.0085

==== Epoch 34/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.71it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6067 | Val Loss: 4.6392 | Val Acc: 0.0342 | Top-5: 0.1257 | F1: 0.0083

==== Epoch 35/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.67it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6070 | Val Loss: 4.6392 | Val Acc: 0.0337 | Top-5: 0.1267 | F1: 0.0075

==== Epoch 36/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.71it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6072 | Val Loss: 4.6398 | Val Acc: 0.0342 | Top-5: 0.1271 | F1: 0.0082

==== Epoch 37/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6046 | Val Loss: 4.6397 | Val Acc: 0.0352 | Top-5: 0.1247 | F1: 0.0083

==== Epoch 38/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train Loss: 4.6062 | Val Loss: 4.6386 | Val Acc: 0.0337 | Top-5: 0.1247 | F1: 0.0076
Train:   0%|          | 0/128 [00:00<?, ?it/s]
==== Epoch 39/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6059 | Val Loss: 4.6400 | Val Acc: 0.0347 | Top-5: 0.1271 | F1: 0.0091

==== Epoch 40/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:12<00:00,  2.66it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6066 | Val Loss: 4.6396 | Val Acc: 0.0347 | Top-5: 0.1276 | F1: 0.0087

==== Epoch 41/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6051 | Val Loss: 4.6406 | Val Acc: 0.0333 | Top-5: 0.1271 | F1: 0.0087

==== Epoch 42/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6069 | Val Loss: 4.6398 | Val Acc: 0.0347 | Top-5: 0.1262 | F1: 0.0082

==== Epoch 43/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:12<00:00,  2.66it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6063 | Val Loss: 4.6390 | Val Acc: 0.0337 | Top-5: 0.1267 | F1: 0.0075

==== Epoch 44/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.34it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.71it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6071 | Val Loss: 4.6394 | Val Acc: 0.0337 | Top-5: 0.1262 | F1: 0.0075

==== Epoch 45/50 ====
Train: 100%|██████████| 128/128 [01:35<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.71it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6070 | Val Loss: 4.6388 | Val Acc: 0.0342 | Top-5: 0.1252 | F1: 0.0077

==== Epoch 46/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.70it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6059 | Val Loss: 4.6401 | Val Acc: 0.0328 | Top-5: 0.1267 | F1: 0.0071

==== Epoch 47/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train Loss: 4.6071 | Val Loss: 4.6391 | Val Acc: 0.0337 | Top-5: 0.1271 | F1: 0.0079

==== Epoch 48/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6066 | Val Loss: 4.6391 | Val Acc: 0.0323 | Top-5: 0.1262 | F1: 0.0072

==== Epoch 49/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.69it/s]
Train:   0%|          | 0/128 [00:00<?, ?it/s]Train Loss: 4.6069 | Val Loss: 4.6403 | Val Acc: 0.0342 | Top-5: 0.1276 | F1: 0.0089

==== Epoch 50/50 ====
Train: 100%|██████████| 128/128 [01:36<00:00,  1.33it/s]
Val: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]
Train Loss: 4.6051 | Val Loss: 4.6393 | Val Acc: 0.0352 | Top-5: 0.1257 | F1: 0.0092
收敛到最优Val Loss Epoch: 38，总训练用时: 91.13 分钟
D:/homework/Course_Design_of_artificial_intelligence/third/ResNet_Seblock/fangzhang_ResNet_kaggle_dalao/sam_dalao_before_seblock/newV1_data.py:243: MatplotlibDeprecationWarning: Support for FigureCanvases without a required_interactive_framework attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.
  plt.figure()
D:/homework/Course_Design_of_artificial_intelligence/third/ResNet_Seblock/fangzhang_ResNet_kaggle_dalao/sam_dalao_before_seblock/newV1_data.py:253: MatplotlibDeprecationWarning: Support for FigureCanvases without a required_interactive_framework attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.
  plt.figure()
SpeedTest: 100%|██████████| 64/64 [00:12<00:00,  5.04it/s]
推理平均测试速度: 2.022 ms/图像
推理最大显存占用: 376.19 MB
Kaggle Test: 100%|██████████| 162/162 [02:00<00:00,  1.34it/s]
Kaggle提交文件保存至: D:\homework\Course_Design_of_artificial_intelligence\third\ResNet_Seblock\fangzhang_ResNet_kaggle_dalao\sam_dalao_before_seblock\newV1_sgd_data_modify\submission_se.csv

进程已结束,退出代码0
